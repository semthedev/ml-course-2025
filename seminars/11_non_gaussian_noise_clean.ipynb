{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semthedev/ml-course-2025/blob/main/seminars/11_non_gaussian_noise_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f450c5ec-6698-4513-a5f1-fb9bb819ad45",
      "metadata": {
        "id": "f450c5ec-6698-4513-a5f1-fb9bb819ad45"
      },
      "source": [
        "# 07. Case study: non-gaussian noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ca0307-9f58-430a-b70b-813808aa68a4",
      "metadata": {
        "id": "e5ca0307-9f58-430a-b70b-813808aa68a4"
      },
      "source": [
        "%load_ext jupyter_black"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cff55bc-2601-471b-9d02-a223127cf10a",
      "metadata": {
        "id": "5cff55bc-2601-471b-9d02-a223127cf10a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "73d10bbb-5549-41ec-af3c-afc133472a01",
      "metadata": {
        "id": "73d10bbb-5549-41ec-af3c-afc133472a01"
      },
      "source": [
        "Сначала немного вспомним, какие вероятностные предположнеия мы делали в обычной регрессии.\n",
        "\n",
        "Собственно, линейная зависимость $\\mathbf{y}$ от $\\mathbf{x}$:\n",
        "\n",
        "$$y(\\mathbf{x}, \\mathbf{w}) = \\sum_{j=0}^{M-1}{w_j x_j} = \\mathbf{w}^T \\mathbf{x} \\tag{1}$$\n",
        "\n",
        "Далее, говорим что в настоящих данных метки с шумом:\n",
        "$$\n",
        "t = y(\\mathbf{x}, \\mathbf{w}) + \\epsilon \\tag{2}\n",
        "$$\n",
        "\n",
        "Который (важно):\n",
        "1. Имеет нормальное распределение с нулевым средним\n",
        "2. Гомоскедастичен (то есть, не зависит от x)\n",
        "3. Независим в совокупности (то есть, шум в каждой точке данных - множество независимых в совокупности с.в.)\n",
        "\n",
        "Правдоподобие одной точки данных:\n",
        "$$\n",
        "p(t \\lvert \\mathbf{x}, \\mathbf{w}, \\beta) =\n",
        "\\mathcal{N}(t \\lvert y(\\mathbf{x}, \\mathbf{w}), \\beta^{-1}) =\n",
        "\\sqrt{\\beta \\over {2 \\pi}} \\exp\\left(-{\\beta \\over 2} (t - y(\\mathbf{x}, \\mathbf{w}))^2 \\right) \\tag{3}\n",
        "$$\n",
        "\n",
        "Наконец, полное правдоподобие:\n",
        "\n",
        "$$\n",
        "p(\\mathbf{t} \\lvert \\mathbf{X}, \\mathbf{w}, \\beta) =\n",
        "\\prod_{i=1}^{N}{\\mathcal{N}(t_i \\lvert \\mathbf{w}^T \\mathbf{x_i}, \\beta^{-1})} \\tag{4}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516b804e-a69b-49a5-ae88-f2e0cf9d2b34",
      "metadata": {
        "id": "516b804e-a69b-49a5-ae88-f2e0cf9d2b34"
      },
      "source": [
        "Помните полиномиальную регрессию с лекций, где в качестве $X$ мы подставляли степени одной-единственной независимой переменной $x$? Так вот, в литературе такой трюк называется **design matrix**, и конечно вместо степеней можно подставлять абсолютно что угодо.\n",
        "\n",
        "$$\n",
        "\\boldsymbol\\Phi =\n",
        "\\begin{pmatrix}\n",
        "\\phi_0(\\mathbf{x}_1) &  \\phi_1(\\mathbf{x}_1) & \\cdots & \\phi_{M-1}(\\mathbf{x}_1) \\\\\n",
        "\\phi_0(\\mathbf{x}_2) &  \\phi_1(\\mathbf{x}_2) & \\cdots & \\phi_{M-1}(\\mathbf{x}_2) \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "\\phi_0(\\mathbf{x}_N) &  \\phi_1(\\mathbf{x}_N) & \\cdots & \\phi_{M-1}(\\mathbf{x}_N)\n",
        "\\end{pmatrix} \\tag{7}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120713a5-7484-440a-8fd7-116d84d0b2ee",
      "metadata": {
        "id": "120713a5-7484-440a-8fd7-116d84d0b2ee"
      },
      "source": [
        "В большинстве случаев предположение о том, что шум имеет нормальное распределение - абсолютно логичное, благодаря ЦПТ. Но там, где условия ЦПТ нарушаются (какие там условия, кстати? а кто может привести пример?), возникают другие респределения.\n",
        "\n",
        "Например, экспоненциальное распределение - это распределение интервалов между равномерно распределенными с.в. Так что если, например, вы измеряете время какого-то процесса, и оно замеряется с задержкой - вы получите экспоненциальный шум. В жизни экспоненциальное респределение имеют, например, паузы между щелчками счетчика Гейгера."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e382ffa2-980c-4306-ba3c-9e9f31920207",
      "metadata": {
        "id": "e382ffa2-980c-4306-ba3c-9e9f31920207"
      },
      "source": [
        "# Синтетические данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5406cc3b-069c-4533-87ba-9c43f173f340",
      "metadata": {
        "id": "5406cc3b-069c-4533-87ba-9c43f173f340"
      },
      "source": [
        "def f_true(x):\n",
        "    return (x - 3) ** 2\n",
        "\n",
        "\n",
        "x = np.linspace(1, 10, 100)\n",
        "x_observed = np.random.choice(x, size=500, replace=True)\n",
        "y_observed = f_true(x_observed) + np.random.exponential(2.0, len(x_observed))\n",
        "\n",
        "plt.plot(x, f_true(x), c=\"grey\", label=\"true function\")\n",
        "plt.scatter(x_observed, y_observed, s=1.0, label=\"observations\")\n",
        "plt.legend()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fc37d737-a353-4411-9f69-d8006458ce32",
      "metadata": {
        "id": "fc37d737-a353-4411-9f69-d8006458ce32"
      },
      "source": [
        "# Обычная регресссия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c395f6d-9d51-4bec-ad13-5247352588b3",
      "metadata": {
        "id": "5c395f6d-9d51-4bec-ad13-5247352588b3"
      },
      "source": [
        "...\n",
        "\n",
        "plt.plot(x, f_true(x), c=\"grey\", label=\"true function\")\n",
        "plt.plot(x, y_pred, c=\"red\", label=\"predicted\")\n",
        "plt.scatter(x_observed, y_observed, s=1.0, label=\"observations\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fdc13d66-70ff-4d9e-b85a-20f9a4dd660c",
      "metadata": {
        "id": "fdc13d66-70ff-4d9e-b85a-20f9a4dd660c"
      },
      "source": [
        "# Обычная регресссия + полиномиальный базис"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c1cad0-3b63-46be-ad27-0320d1bac3f0",
      "metadata": {
        "id": "94c1cad0-3b63-46be-ad27-0320d1bac3f0"
      },
      "source": [
        "def get_design(x):\n",
        "  ...\n",
        "\n",
        "get_design(np.array([1, 2, 3]))"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3df83e-6d4f-4a8d-92bd-7caf5246a69a",
      "metadata": {
        "id": "ec3df83e-6d4f-4a8d-92bd-7caf5246a69a"
      },
      "source": [
        "regr = LinearRegression()\n",
        "regr.fit(get_design(x_observed), y_observed)\n",
        "y_pred = regr.predict(get_design(x))\n",
        "\n",
        "plt.plot(x, f_true(x), c=\"grey\", label=\"true function\")\n",
        "plt.plot(x, y_pred, c=\"red\", label=\"predicted\")\n",
        "plt.scatter(x_observed, y_observed, s=1.0, label=\"observations\")\n",
        "plt.legend()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "88c78a63-b1d9-4906-969b-4a4764a88da7",
      "metadata": {
        "id": "88c78a63-b1d9-4906-969b-4a4764a88da7"
      },
      "source": [
        "# Линейная регрессия с экспоненциальным распределением шума"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a07c501-85ce-457e-b3dd-68da0d465c36",
      "metadata": {
        "id": "2a07c501-85ce-457e-b3dd-68da0d465c36"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "def log_likelihood(X, y, W, _lambda=1):\n",
        "    \"\"\"\n",
        "    PDF: lambda * exp (-lambda * x)\n",
        "\n",
        "    :param X_data: observable features with (bias term at first coordinate)\n",
        "                    expected shape: (n_samples, n_features + 1)\n",
        "    :param y: observable target\n",
        "                    expected shape: (n_samples)\n",
        "    :param W: weight matrix (with bias term at first coordinate):\n",
        "                    expexted_shape: (n_features + 1, )\n",
        "    \"\"\"\n",
        "\n",
        "    return ...\n",
        "\n",
        "\n",
        "def add_bias_to_features(X):\n",
        "    X = np.concatenate([np.ones_like(X)[:, 0:1], X], axis=-1)\n",
        "    return X\n",
        "\n",
        "\n",
        "X = add_bias_to_features(x_observed[:, None])\n",
        "\n",
        "print(\"Negative Log Likelihood:\", -log_likelihood(X, y_observed, np.zeros(2)))"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2c24ef36-8f9b-44ee-83a8-725fc012f4f9",
      "metadata": {
        "id": "2c24ef36-8f9b-44ee-83a8-725fc012f4f9"
      },
      "source": [
        "Как вы наверное помните с лекций, максимизация полного правдоподобия линейной модели **с нормальным шумом** - это в точности минимизация суммы квадратов отклонений, а еще для нее можно провести честный байесовский вывод.\n",
        "\n",
        "С другим распроеделением шума, оба утверждения неверны. Во-первых, оптимизировать надо иначе (почему?), во-вторых вывести ничего не выйдет."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b76c43-01c0-4f5b-bbf6-afca75d62a0a",
      "metadata": {
        "id": "94b76c43-01c0-4f5b-bbf6-afca75d62a0a"
      },
      "source": [
        "W = np.zeros(X.shape[-1]).T\n",
        "\n",
        "...\n",
        "\n",
        "print(\"Negative Log Likelihood:\", likelihood)\n",
        "print(\"Optimum:\", W_optimal)\n",
        "plt.plot(x, f_true(x), c=\"grey\", label=\"true function\")\n",
        "plt.plot(x, add_bias_to_features(x[:, None]) @ W_optimal, c=\"red\", label=\"predicted\")\n",
        "plt.scatter(x_observed, y_observed, s=1.0, label=\"observations\")\n",
        "plt.legend()"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388a3b65-69bd-4b51-9c44-3719e90fddef",
      "metadata": {
        "id": "388a3b65-69bd-4b51-9c44-3719e90fddef"
      },
      "source": [
        "ax = sns.heatmap(grid_values, cmap=\"coolwarm\", center=grid_values.mean())\n",
        "x_ticks = np.arange(slices[0].start, slices[0].stop, slices[0].step)\n",
        "y_ticks = np.arange(slices[1].start, slices[1].stop, slices[1].step)\n",
        "ax.set_xticks(np.linspace(0, len(x_ticks) - 1, num=6))  # Adjust the number of ticks\n",
        "ax.set_yticks(np.linspace(0, len(y_ticks) - 1, num=6))\n",
        "ax.set_xticklabels(\n",
        "    [f\"{tick:.1f}\" for tick in np.linspace(slices[0].start, slices[0].stop, num=6)]\n",
        ")\n",
        "ax.set_yticklabels(\n",
        "    [f\"{tick:.1f}\" for tick in np.linspace(slices[1].start, slices[1].stop, num=6)]\n",
        ")\n",
        "ax.set_title(\"Negative Log-Likelihood Heatmap\")\n",
        "\n",
        "y_idx = int((W_optimal[0] - slices[0].start) / slices[0].step)\n",
        "x_idx = int((W_optimal[1] - slices[1].start) / slices[1].step)\n",
        "plt.scatter(x_idx, y_idx, marker=\"*\", color=\"red\", s=200, label=\"W_optimal\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8fae92a2-70bc-45a8-8325-89cf016851bc",
      "metadata": {
        "id": "8fae92a2-70bc-45a8-8325-89cf016851bc"
      },
      "source": [
        "# Экспоненциальный шум + полиномиальный базис"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6596954-4447-4f07-b379-b9518b759116",
      "metadata": {
        "id": "c6596954-4447-4f07-b379-b9518b759116"
      },
      "source": [
        "X = add_bias_to_features(get_design(x_observed))\n",
        "W = np.ones(X.shape[-1]).T\n",
        "\n",
        "...\n",
        "\n",
        "print(\"Negative Log Likelihood:\", likelihood)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2498b2-c61e-4d79-9dbc-283a3fa8a980",
      "metadata": {
        "id": "3b2498b2-c61e-4d79-9dbc-283a3fa8a980"
      },
      "source": [
        "print(\"Optimum:\", W_optimal)\n",
        "plt.plot(x, f_true(x), c=\"grey\", label=\"true function\")\n",
        "plt.plot(x, add_bias_to_features(get_design(x)) @ W_optimal, c=\"red\", label=\"predicted\")\n",
        "plt.scatter(x_observed, y_observed, s=1.0, label=\"observations\")\n",
        "plt.legend()"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0e7a7e6c-b9be-4796-b1b1-2d3783db2d99",
      "metadata": {
        "id": "0e7a7e6c-b9be-4796-b1b1-2d3783db2d99"
      },
      "source": [
        "# Case study: Robust linear regression\n",
        "\n",
        "Предыдущий пример был интересный концептуально, но на самом-то деле не очень практичный. Теперь более практичный сюжет:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f69372-3992-4307-afa6-7ef78b536d42",
      "metadata": {
        "id": "a2f69372-3992-4307-afa6-7ef78b536d42"
      },
      "source": [
        "# снова сгенерированные даные\n",
        "\n",
        "N_SAMPLES = 500\n",
        "N_OUTLIERS = 25\n",
        "\n",
        "X, y, coef = datasets.make_regression(\n",
        "    n_samples=N_SAMPLES,\n",
        "    n_features=1,\n",
        "    n_informative=1,\n",
        "    noise=20,\n",
        "    coef=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "coef_list = [[\"original_coef\", float(coef)]]\n",
        "\n",
        "# add outliers\n",
        "np.random.seed(42)\n",
        "X[:N_OUTLIERS] = 10 + 0.75 * np.random.normal(size=(N_OUTLIERS, 1))\n",
        "y[:N_OUTLIERS] = -15 + 20 * np.random.normal(size=N_OUTLIERS)\n",
        "\n",
        "plt.scatter(X, y);"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5ead65b1-096a-423f-b492-bb24acf2902a",
      "metadata": {
        "id": "5ead65b1-096a-423f-b492-bb24acf2902a"
      },
      "source": [
        "Казалось бы, есть линейная модель, есть данные которые явно имеют линейную природу. Ну добавили к ним 5% каких-то выбросов, что может пойти не так?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a4ab36e-be08-469b-b3f0-26527e49a881",
      "metadata": {
        "id": "9a4ab36e-be08-469b-b3f0-26527e49a881"
      },
      "source": [
        "lr = LinearRegression().fit(X, y)\n",
        "coef_list.append([\"linear_regression\", lr.coef_[0]])\n",
        "\n",
        "plotline_X = np.arange(X.min(), X.max()).reshape(-1, 1)\n",
        "fit_df = pd.DataFrame(\n",
        "    index=plotline_X.flatten(), data={\"linear_regression\": lr.predict(plotline_X)}\n",
        ")\n",
        "\n",
        "fix, ax = plt.subplots()\n",
        "fit_df.plot(ax=ax)\n",
        "plt.scatter(X, y, c=\"k\")\n",
        "plt.title(\"Linear regression on data with outliers\");"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dad74d49-c1a7-4c28-8cde-48a39a04c04b",
      "metadata": {
        "id": "dad74d49-c1a7-4c28-8cde-48a39a04c04b"
      },
      "source": [
        "### И что теперь делать?\n",
        "\n",
        "Есть целое семейство линейных моделей, которые менее чувствительны к выбросам. Про какие-то из них (Huber, RANSAC) мы поговорим через одно занятие, а сегодня придумаем что-нибудь на коленке. Что предложите?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8548207-3f2e-4df0-9d29-c9445559f7df",
      "metadata": {
        "id": "c8548207-3f2e-4df0-9d29-c9445559f7df"
      },
      "source": [
        "from scipy.stats import t\n",
        "\n",
        "\n",
        "def log_likelihood(X, y, w, df=1):\n",
        "    ...\n",
        "\n",
        "\n",
        "log_likelihood(X, y, np.array([0, 100]))"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53392aca-594c-49ff-8892-b27a4aaf1dea",
      "metadata": {
        "id": "53392aca-594c-49ff-8892-b27a4aaf1dea"
      },
      "source": [
        "df = 1\n",
        "res = ...\n",
        "res"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb843021-3793-4598-9bb0-066cca135db2",
      "metadata": {
        "id": "fb843021-3793-4598-9bb0-066cca135db2"
      },
      "source": [
        "## ...но есть нюанс\n",
        "\n",
        "res = ...\n",
        "fit_df[\"t-noise@(0,0)\"] = pd.DataFrame(\n",
        "    index=plotline_X.flatten(),\n",
        "    data={\"linear_regression\": plotline_X[:, 0] * res.x[0] + res.x[1]},\n",
        ")\n",
        "\n",
        "fix, ax = plt.subplots()\n",
        "fit_df.plot(ax=ax)\n",
        "plt.scatter(X, y, c=\"k\")\n",
        "plt.title(\"Linear regression on data with outliers\");"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a0e55151-63d9-4b67-8ffa-41f0a1d17d46",
      "metadata": {
        "id": "a0e55151-63d9-4b67-8ffa-41f0a1d17d46"
      },
      "source": [
        "Впрочем, ничего нового, градиентный метод сошелся в локальный оптимум."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3fef6bb-9d4d-4587-b20f-a29bed413597",
      "metadata": {
        "id": "f3fef6bb-9d4d-4587-b20f-a29bed413597"
      },
      "source": [
        "::\\\\#### Задача со звездочкой 8: Экспоненциальный шум (2 балла)\n",
        "Придумать и реализовать более умную оптимизацию линейной регрессии с экспоненциальным шумом, чем полным перебором по пространству весов. Правильный ответ должен быть **неотличим на глаз** от предсказаний модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7191221c-299c-41fc-8de1-3743055cf60f",
      "metadata": {
        "id": "7191221c-299c-41fc-8de1-3743055cf60f"
      },
      "source": [
        "..."
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d50c6c8b-ae13-4542-9b32-1e7c55000475",
      "metadata": {
        "id": "d50c6c8b-ae13-4542-9b32-1e7c55000475"
      },
      "source": [
        "#### Задача со звездочкой 9: Эллипс\n",
        "\n",
        "Вы оказались одни в лесу, и вам очень надо восстановить уравнение эллипса по данным. Как на зло, все что у вас есть - это `sklearn.linear_model.LinearRegression`.\n",
        "\n",
        "**1 балл.** К счастью, вы знаете что эллипс не абы какой, а с осями, параллельными осям координат.\n",
        "\n",
        "**1 балл.** А теперь не знаете. (WARNING: я не уверен в том, что это возможно c `LinearRegression`, но OLS может)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b52b92-b431-4ee6-befb-8edba2707387",
      "metadata": {
        "id": "e0b52b92-b431-4ee6-befb-8edba2707387"
      },
      "source": [
        "# Правильный ответ\n",
        "CENTER_X = -5.0\n",
        "CENTER_Y = 2.0\n",
        "SCALE_X = 2.0\n",
        "SCALE_Y = 3.0\n",
        "ANGLE = np.pi / 6"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "859b936f-0550-4e54-bc1c-fe99763fab8f",
      "metadata": {
        "id": "859b936f-0550-4e54-bc1c-fe99763fab8f"
      },
      "source": [
        "# Генерируем данные\n",
        "x = np.random.rand(100) * 2 - 1\n",
        "y_pos = np.sqrt(1 - x**2) + np.random.normal(0, 0.1, 100)\n",
        "y_neg = -np.sqrt(1 - x**2) + np.random.normal(0, 0.1, 100)\n",
        "y = np.hstack([y_pos, y_neg])\n",
        "x = x * SCALE_X - CENTER_X\n",
        "y = y * SCALE_Y - CENTER_Y\n",
        "x = np.hstack([x, x])\n",
        "data = np.stack([x, y], axis=1)\n",
        "plt.scatter(data[:, 0], data[:, 1])"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eb0eef1a-2c12-4cb0-a8ba-284516ab7621",
      "metadata": {
        "id": "eb0eef1a-2c12-4cb0-a8ba-284516ab7621"
      },
      "source": [
        "---\n",
        "This notebook is based on Nvidia [article](https://github.com/erykml/nvidia_articles/blob/main/robust_regression.ipynb) on robust regression."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}